{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f1af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 1 import image\n",
    "%matplotlib inline\n",
    "import torchvision.datasets\n",
    "import math\n",
    "import torchvision.transforms as tvt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wget\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as tfms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from transformers import ViTConfig, ViTModel\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "image_size = 64\n",
    "batch_size = 1024\n",
    "dataset = torchvision.datasets.CelebA(\"../../celeba/datasets/\",split='train', transform=tvt.Compose([\n",
    "                                  tvt.Resize((image_size,image_size)),\n",
    "                                  tvt.ToTensor(),\n",
    "                                  tvt.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                std=[0.5, 0.5, 0.5])\n",
    "                              ]))\n",
    "\n",
    "test_dataset = torchvision.datasets.CelebA(\"../../celeba/datasets/\",split='test', transform=tvt.Compose([\n",
    "                                  tvt.Resize((image_size,image_size)),\n",
    "                                  tvt.ToTensor(),\n",
    "                                  tvt.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                std=[0.5, 0.5, 0.5])\n",
    "                              ]))\n",
    "\n",
    "training_data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c384d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher_VisionTransformer(nn.Module):\n",
    "    def __init__(self, vit):\n",
    "        super(Teacher_VisionTransformer, self).__init__()\n",
    "        self.vit = vit\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),     \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.vit(x)\n",
    "        m = z.last_hidden_state\n",
    "        g = m[:,0]\n",
    "        y = self.seq(g)\n",
    "        return y \n",
    "    \n",
    "class Student_VisionTransformer(nn.Module):\n",
    "    def __init__(self, vit):\n",
    "        super(Student_VisionTransformer, self).__init__()\n",
    "        self.vit = vit\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1),     \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.vit(x)\n",
    "        m = z.last_hidden_state\n",
    "        g = m[:,0]\n",
    "        y = self.seq(g)\n",
    "        return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e5bd3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Changes the seed for reproducibility. \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_model():\n",
    "    epoch = 15\n",
    "    teacher_configuration = ViTConfig(num_hidden_layers = 12, num_attention_heads = 8, \n",
    "                          intermediate_size = 768, image_size= 64, patch_size = 16)\n",
    "    \n",
    "    student_configuration = ViTConfig(num_hidden_layers = 8, num_attention_heads = 8, \n",
    "                          intermediate_size = 768, image_size= 64, patch_size = 16)\n",
    "    \n",
    "    vit_teacher = ViTModel(teacher_configuration)\n",
    "    vit_student = ViTModel(student_configuration)\n",
    "\n",
    "    vit_teacher = vit_teacher.to(device)\n",
    "    vit_student = vit_student.to(device)\n",
    "\n",
    "    model = Teacher_VisionTransformer(vit_teacher)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    PATH2 = r'knowledge_distillation.pt'\n",
    "\n",
    "    sensitive_epoch = 20\n",
    "    student_model = Student_VisionTransformer(vit_student)\n",
    "    student_model = student_model.to(device)\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    criterion_student = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    student_optimizer = optim.AdamW(student_model.parameters(), lr=1e-4)\n",
    "    lambda_coeff = 1\n",
    "\n",
    "    \n",
    "    for epoches in range(epoch):\n",
    "        with tqdm(training_data_loader, unit=\"batch\") as tepoch:\n",
    "            for train_input, attributes in tepoch:\n",
    "                # Transfer data to GPU if possible. \n",
    "                train_input = train_input.to(device)\n",
    "                sensitive, train_target = attributes[:,20], attributes[:,2]\n",
    "                train_target = train_target.float().to(device)\n",
    "                train_target = train_target.unsqueeze(1)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Learner update step.\n",
    "                outputs = model(train_input)\n",
    "                loss = criterion(outputs, train_target)\n",
    "                loss.backward()\n",
    "                #logger_learner.add_values(logging_dict)\n",
    "                optimizer.step()\n",
    "                tepoch.set_description(f\"epoch %2f \" % epoches)\n",
    "                tepoch.set_postfix(loss = loss.item())\n",
    "\n",
    "            if epoches == epoch-1:\n",
    "                torch.save(model.state_dict(), PATH2)\n",
    "                \n",
    "\n",
    "\n",
    "    model.load_state_dict(torch.load(PATH2), True)\n",
    "        \n",
    "    for epoches in range(sensitive_epoch):\n",
    "        model.eval()\n",
    "        student_model.train()\n",
    "        with tqdm(training_data_loader, unit=\"batch\") as tepoch:\n",
    "            for train_input, attributes in tepoch:\n",
    "                # Transfer data to GPU if possible. \n",
    "                train_input = train_input.to(device)\n",
    "                sensitive, train_target = attributes[:,20], attributes[:,2]\n",
    "                train_target = train_target.float().to(device)\n",
    "                train_target = train_target.unsqueeze(1)\n",
    "                #optimizer.zero_grad()\n",
    "                student_optimizer.zero_grad()\n",
    "\n",
    "                # Learner update step.\n",
    "                student_output = student_model(train_input)\n",
    "                soft_label = model(train_input)\n",
    "                \n",
    "                loss_soft = criterion_student(student_output ,soft_label)\n",
    "                loss_hard = criterion_student(student_output, train_target)\n",
    "                loss = lambda_coeff * loss_soft + (1 - lambda_coeff) * loss_hard \n",
    "                loss.backward()\n",
    "                #logger_learner.add_values(logging_dict)\n",
    "                #optimizer.step()\n",
    "                student_optimizer.step()\n",
    "                tepoch.set_description(f\"epoch %2f \" % epoches)\n",
    "                tepoch.set_postfix(loss = loss.item())\n",
    "                \n",
    "        student_model.eval()\n",
    "        test_pred = []\n",
    "        test_gt = []\n",
    "        sense_gt = []\n",
    "        female_predic = []\n",
    "        female_gt = []\n",
    "        male_predic = []\n",
    "        male_gt = []\n",
    "\n",
    "        for step, (test_input, attributes) in enumerate(test_data_loader):\n",
    "            test_sensitive, test_target = attributes[:,20], attributes[:,2]\n",
    "            test_input = test_input.to(device)\n",
    "            test_target = test_target.to(device)\n",
    "            test_target = test_target.unsqueeze(1)\n",
    "            test_sensitive = test_sensitive.unsqueeze(1)\n",
    "\n",
    "            gt = test_target.detach().cpu().numpy()\n",
    "            sen = test_sensitive.detach().cpu().numpy()\n",
    "            test_gt.extend(gt)\n",
    "            sense_gt.extend(sen)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                test_pred_= student_model(test_input)   \n",
    "                test_pred.extend(torch.round(test_pred_.squeeze(1)).detach().cpu().numpy())\n",
    "\n",
    "        for i in range(len(sense_gt)):\n",
    "            if sense_gt[i] == 0:\n",
    "                female_predic.append(test_pred[i])\n",
    "                female_gt.append(test_gt[i])\n",
    "            else:\n",
    "                male_predic.append(test_pred[i])\n",
    "                male_gt.append(test_gt[i])\n",
    "        female_CM = confusion_matrix(female_gt, female_predic)    \n",
    "        male_CM = confusion_matrix(male_gt, male_predic) \n",
    "        female_dp = (female_CM[1][1]+female_CM[0][1])/(female_CM[0][0]+female_CM[0][1]+female_CM[1][0]+female_CM[1][1])\n",
    "        male_dp = (male_CM[1][1]+male_CM[0][1])/(male_CM[0][0]+male_CM[0][1]+male_CM[1][0]+male_CM[1][1])\n",
    "        female_TPR = female_CM[1][1]/(female_CM[1][1]+female_CM[1][0])\n",
    "        male_TPR = male_CM[1][1]/(male_CM[1][1]+male_CM[1][0])\n",
    "        female_FPR = female_CM[0][1]/(female_CM[0][1]+female_CM[0][0])\n",
    "        male_FPR = male_CM[0][1]/(male_CM[0][1]+male_CM[0][0])\n",
    "\n",
    "        print('Female TPR', female_TPR)\n",
    "        print('male TPR', male_TPR)\n",
    "        print('DP',abs(female_dp - male_dp))\n",
    "        print('EOP', abs(female_TPR - male_TPR))\n",
    "        print('EoD',0.5*(abs(female_FPR-male_FPR)+ abs(female_TPR-male_TPR)))\n",
    "        print('acc', accuracy_score(test_gt, test_pred))\n",
    "        print('Trade off',accuracy_score(test_gt, test_pred)*(1-0.5*(abs(female_FPR-male_FPR)+ abs(female_TPR-male_TPR))) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "seed_everything(4096)    \n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLcourse]",
   "language": "python",
   "name": "conda-env-DLcourse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
