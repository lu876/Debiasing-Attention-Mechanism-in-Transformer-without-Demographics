{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03a58a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shenyu/miniconda3/envs/DLcourse/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "#step 1 import image\n",
    "%matplotlib inline\n",
    "import torchvision.datasets\n",
    "import math\n",
    "import torchvision.transforms as tvt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wget\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as tfms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset, random_split\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from transformers import ViTModel\n",
    "\n",
    "device = torch.device('cuda:1')\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Changes the seed for reproducibility. \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything(1024)\n",
    "image_size = 64\n",
    "batch_size = 256\n",
    "dataset = torchvision.datasets.CelebA(\"../../../../celeba/datasets/\",split='train', transform=tvt.Compose([\n",
    "                                  tvt.Resize((image_size,image_size)),\n",
    "                                  tvt.ToTensor(),\n",
    "                                  tvt.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                std=[0.5, 0.5, 0.5])                                  \n",
    "                              ]))\n",
    "\n",
    "test_dataset = torchvision.datasets.CelebA(\"../../../../celeba/datasets/\",split='test', transform=tvt.Compose([\n",
    "                                  tvt.Resize((image_size,image_size)),\n",
    "                                  tvt.ToTensor(),\n",
    "                                  tvt.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                                std=[0.5, 0.5, 0.5])                                  \n",
    "                              ]))\n",
    "\n",
    "# lengths = [int(len(dataset)*0.9), int(len(dataset)*0.1)]\n",
    "# if sum(lengths) != len(dataset):\n",
    "#     lengths[0] += len(dataset) - sum(lengths)\n",
    "    \n",
    "# train_dataset, val_dataset = random_split(dataset, lengths)\n",
    "\n",
    "training_data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c5dc369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, vit):\n",
    "        super(VisionTransformer, self).__init__()\n",
    "        self.vit = vit\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.vit(x)\n",
    "        m = z.last_hidden_state\n",
    "        g = m[:,0]\n",
    "        y = self.seq(g)\n",
    "        return y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "890e30b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0.000000 : 100%|██████████████████████████████████████████████| 635/635 [04:22<00:00,  2.42batch/s, ut_loss=0.127]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9388838793708045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1.000000 : 100%|██████████████████████████████████████████████| 635/635 [04:20<00:00,  2.44batch/s, ut_loss=0.113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9451958721570984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 2.000000 : 100%|██████████████████████████████████████████████| 635/635 [04:25<00:00,  2.39batch/s, ut_loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9424406372107004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 3.000000 : 100%|██████████████████████████████████████████████| 635/635 [04:22<00:00,  2.42batch/s, ut_loss=0.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9481514878268711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 4.000000 : 100%|██████████████████████████████████████████████| 635/635 [04:21<00:00,  2.43batch/s, ut_loss=0.122]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9472497745716862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 5.000000 :  18%|████████▍                                     | 117/635 [00:49<03:26,  2.51batch/s, ut_loss=0.126]IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "epoch 7.000000 : 100%|██████████████████████████████████████████████| 635/635 [03:57<00:00,  2.67batch/s, ut_loss=0.139]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9472497745716862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 8.000000 : 100%|██████████████████████████████████████████████| 635/635 [04:24<00:00,  2.40batch/s, ut_loss=0.112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.946899108305781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9.000000 : 100%|█████████████████████████████████████████████| 635/635 [04:22<00:00,  2.42batch/s, ut_loss=0.0756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9459973950505961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 10.000000 : 100%|█████████████████████████████████████████████| 635/635 [04:19<00:00,  2.45batch/s, ut_loss=0.108]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9455465384230037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 11.000000 : 100%|█████████████████████████████████████████████| 635/635 [04:26<00:00,  2.38batch/s, ut_loss=0.106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9447450155295061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 12.000000 : 100%|████████████████████████████████████████████| 635/635 [04:26<00:00,  2.39batch/s, ut_loss=0.0666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9423905420298567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 13.000000 : 100%|████████████████████████████████████████████| 635/635 [04:13<00:00,  2.51batch/s, ut_loss=0.0741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.943492636008416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 14.000000 : 100%|████████████████████████████████████████████| 635/635 [04:28<00:00,  2.37batch/s, ut_loss=0.0588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.9419897805831079\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from transformers import ViTConfig, ViTModel\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Changes the seed for reproducibility. \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def train_model():\n",
    "    epoch = 15\n",
    "    configuration = ViTConfig(num_hidden_layers = 8, num_attention_heads = 8, \n",
    "                          intermediate_size = 768, image_size= 64, patch_size = 16)\n",
    "    vit = ViTModel(configuration)\n",
    "    configuration = vit.config\n",
    "    vit = vit.to(device)\n",
    "    model = VisionTransformer(vit)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    valid_acc = []\n",
    "    valid_eod = []\n",
    "    save_acc = 0\n",
    "\n",
    "    for epoches in range(epoch):\n",
    "        with tqdm(training_data_loader, unit=\"batch\") as tepoch:\n",
    "            for train_input, attributes in tepoch:\n",
    "                # Transfer data to GPU if possible. \n",
    "                train_input = train_input.to(device)\n",
    "                train_target = attributes[:,9]\n",
    "                train_target = torch.nn.functional.one_hot(train_target, num_classes=2).float().to(device)\n",
    "                optimizer.zero_grad()\n",
    "                # Learner update step.\n",
    "                outputs = model(train_input)\n",
    "                loss = criterion(outputs, train_target)\n",
    "                loss.backward()\n",
    "                #logger_learner.add_values(logging_dict)\n",
    "                optimizer.step()\n",
    "                tepoch.set_description(f\"epoch %2f \" % epoches)\n",
    "                tepoch.set_postfix(ut_loss = loss.item())        \n",
    "        test_pred = []\n",
    "        test_gt = [] \n",
    "\n",
    "    # Evaluate on valdi set.\n",
    "        for step, (test_input, attributes) in enumerate(test_data_loader):\n",
    "            test_target = attributes[:,9]\n",
    "            test_input = test_input.to(device)\n",
    "            test_target = test_target.to(device)\n",
    "            gt = test_target.detach().cpu().numpy()\n",
    "            test_gt.extend(gt)\n",
    "            with torch.no_grad():\n",
    "                test_pred_ = model(test_input)\n",
    "                _, predicted = torch.max(test_pred_.data, 1)\n",
    "                test_pred.extend(predicted.cpu().numpy())\n",
    "        test_acc = accuracy_score(test_gt, test_pred)\n",
    "        print('acc', test_acc)\n",
    "\n",
    "        if test_acc > save_acc:\n",
    "            save_acc = test_acc\n",
    "            torch.save(model.state_dict(), f'mode.pth')\n",
    "        \n",
    "seed_everything(1024)    \n",
    "train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLcourse]",
   "language": "python",
   "name": "conda-env-DLcourse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
